# Classification Using Levenbergâ€“Marquardt Algorithm

This repository provides a Python implementation of a **classification model** trained using the **Levenbergâ€“Marquardt (LM)** algorithm. While traditionally used for nonlinear regression, LM can be adapted to classification problems by minimizing error over class outputs.

## ğŸ“Œ Problem Definition

The objective is to classify input samples into predefined categories by training a model that minimizes the squared error between predicted outputs and actual class labels.

The cost function is:

```math
\min_{x} \sum_{i=1}^{N} \left(y_i - f(x, t_i)\right)^2
````

Where:

* `x` is the model parameter vector
* `f(x, t_i)` is the predicted output (class probability or label)
* `y_i` is the true label (often one-hot encoded for multi-class)

## ğŸ” Method Overview

The LM algorithm updates model parameters to minimize the squared classification error, using the Jacobian matrix and a damping factor Î» to balance between:

* **Gradient descent** (for stability)
* **Gaussâ€“Newton** (for speed near solution)

Although itâ€™s less common than gradient-based methods like Adam or SGD, LM can achieve fast convergence in small-to-medium classification tasks.

### Key Features:

* Nonlinear classification support
* Fast convergence for smooth cost surfaces
* Good performance when class outputs are modeled continuously

## âš™ï¸ Algorithm Steps

1. Prepare input data and one-hot encoded labels
2. Initialize parameters and damping factor `Î»`
3. While not converged:

   * Compute output and residuals
   * Compute Jacobian
   * Update parameters using LM rule
   * Adjust `Î»` based on performance
4. Output class predictions

# Levenbergâ€“Marquardt AlgoritmasÄ± ile SÄ±nÄ±flandÄ±rma

Bu repoda, **Levenbergâ€“Marquardt (LM)** algoritmasÄ± kullanÄ±larak eÄŸitilmiÅŸ bir **sÄ±nÄ±flandÄ±rma modeli** Python ile uygulanmÄ±ÅŸtÄ±r. LM yÃ¶ntemi genellikle regresyon iÃ§in kullanÄ±lsa da, sÄ±nÄ±flandÄ±rma problemlerinde de hata fonksiyonunu minimize etmek iÃ§in uyarlanabilir.

## ğŸ“Œ Problem TanÄ±mÄ±

AmaÃ§, girdi verilerini belirli sÄ±nÄ±flara ayÄ±rmak ve modelin Ã§Ä±ktÄ±sÄ± ile gerÃ§ek etiketler (label) arasÄ±ndaki hatayÄ± en aza indirmektir.

Maliyet (cost) fonksiyonu ÅŸu ÅŸekildedir:

```math
\min_{x} \sum_{i=1}^{N} \left(y_i - f(x, t_i)\right)^2
````

Burada:

* `x`, modelin parametre vektÃ¶rÃ¼dÃ¼r
* `f(x, t_i)`, tahmin edilen Ã§Ä±ktÄ± (olasÄ±lÄ±k ya da etiket)
* `y_i`, gerÃ§ek sÄ±nÄ±f etiketidir (Ã§ok sÄ±nÄ±flÄ± iÃ§in genelde one-hot encoded kullanÄ±lÄ±r)

## ğŸ” YÃ¶ntem Ã–zeti

LM algoritmasÄ±, sÄ±nÄ±flandÄ±rma hatasÄ±nÄ± azaltmak iÃ§in model parametrelerini gÃ¼nceller. GÃ¼ncelleme sÄ±rasÄ±nda Jacobian matrisi ve sÃ¶nÃ¼mleme faktÃ¶rÃ¼ `Î»` kullanÄ±lÄ±r. BÃ¶ylece:

* **Gradyan iniÅŸ** ile kararlÄ±lÄ±k saÄŸlanÄ±r
* **Gaussâ€“Newton** ile hÄ±z kazandÄ±rÄ±lÄ±r

Her ne kadar SGD veya Adam kadar yaygÄ±n olmasa da, LM algoritmasÄ± kÃ¼Ã§Ã¼k ve orta Ã¶lÃ§ekli sÄ±nÄ±flandÄ±rma problemlerinde hÄ±zlÄ± yakÄ±nsama saÄŸlayabilir.

### Temel Ã–zellikler:

* DoÄŸrusal olmayan sÄ±nÄ±flandÄ±rma destekler
* DÃ¼zgÃ¼n maliyet yÃ¼zeylerinde hÄ±zlÄ± yakÄ±nsar
* SÃ¼rekli Ã§Ä±ktÄ± veren sÄ±nÄ±flandÄ±rÄ±cÄ± yapÄ±lar iÃ§in uygundur

## âš™ï¸ Algoritma AdÄ±mlarÄ±

1. Girdi verisi ve one-hot etiketler hazÄ±rlanÄ±r
2. Parametreler ve sÃ¶nÃ¼mleme katsayÄ±sÄ± `Î»` tanÄ±mlanÄ±r
3. YakÄ±nsama saÄŸlanana kadar:

   * Ã‡Ä±ktÄ±lar ve artÄ±klar hesaplanÄ±r
   * Jacobian matrisi oluÅŸturulur
   * Parametreler LM gÃ¼ncellemesi ile yenilenir
   * `Î»` hata durumuna gÃ¶re gÃ¼ncellenir
4. SÄ±nÄ±f tahminleri Ã¼retilir
