# ğŸ§  Optimization for Machine Learning

This repository presents a practical deep dive into **numerical optimization methods** frequently used in the field of machine learning. The goal is to better understand how optimization drives model performance, generalization, and convergence.

Developed out of personal interest in mathematical foundations of ML, the implementations aim to bridge theoretical understanding with hands-on Python experiments.

---

## ğŸ” Covered Topics

### 1. ğŸ“Œ One-Dimensional Optimization
- Golden Section Method
- Bisection Method
- Newton-Raphson Method

### 2. ğŸ“Œ Multi-Dimensional Optimization
- Steepest Descent
- Conjugate Gradient
- Newton & Quasi-Newton Methods (DFP, BFGS)
- Levenberg-Marquardt Algorithm

### 3. ğŸ¤– Optimization Applications in ML
- Cost Function Minimization
- Loss Surface Analysis
- Curve Fitting
- Training Optimization for Neural Networks
- Regularization Techniques

---

## ğŸ› ï¸ Tools & Libraries
- Python
- NumPy / SciPy
- Matplotlib
- Jupyter Notebook

---

## ğŸ§  Why Optimization?

Optimization is a foundational component of machine learning:
- Tuning model weights and biases
- Minimizing prediction error
- Accelerating convergence in deep learning

This repository offers a structured and hands-on way to grasp these ideas through numerical methods.

---

# ğŸ‡¹ğŸ‡· Makine Ã–ÄŸrenmesi iÃ§in Optimizasyon

Bu proje, **makine Ã¶ÄŸrenmesinde** sÄ±kÃ§a kullanÄ±lan sayÄ±sal optimizasyon tekniklerini anlamaya yÃ¶nelik hazÄ±rlanmÄ±ÅŸtÄ±r. Her yÃ¶ntem, Python ile uygulanmÄ±ÅŸ ve gerÃ§ek problemlerde nasÄ±l kullanÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶steren Ã¶rneklerle desteklenmiÅŸtir.

---

## ğŸ“‚ Ä°Ã§erik

### ğŸ“Œ Tek Boyutlu YÃ¶ntemler:
- AltÄ±n Oran YÃ¶ntemi
- Bisection (Ä°kiye BÃ¶lme)
- Newton-Raphson

### ğŸ“Œ Ã‡ok Boyutlu YÃ¶ntemler:
- En Dik Ä°niÅŸ (Steepest Descent)
- EÅŸlenik Gradyan (Conjugate Gradient)
- Newton & Quasi-Newton (DFP, BFGS)
- Levenberg-Marquardt AlgoritmasÄ±

### ğŸ¤– ML'de KullanÄ±m AlanlarÄ±:
- KayÄ±p fonksiyonu minimizasyonu
- EÄŸri uydurma problemleri
- Sinir aÄŸlarÄ±nda eÄŸitim optimizasyonu
- AÅŸÄ±rÄ± Ã¶ÄŸrenmenin azaltÄ±lmasÄ± (regularizasyon)

---

## ğŸ¯ Hedef

Model eÄŸitiminin altÄ±nda yatan **matematiksel optimizasyon sÃ¼recini** daha iyi kavramak ve ML modellerini daha bilinÃ§li ÅŸekilde optimize etmek.

---

## ğŸ‘¨â€ğŸ’» Developer
**Yusuf Tufan**  
