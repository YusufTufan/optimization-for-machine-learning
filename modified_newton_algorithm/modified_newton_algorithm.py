# ğŸ§  Modified Newton's Method (Gradient-Based Optimization)
# Bu yÃ¶ntem, bir fonksiyonun minimum deÄŸerini bulmak iÃ§in Newton yÃ¶ntemiyle birlikte Ã§izgisel (line search) optimizasyon kullanÄ±r.
# Burada adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ Golden Section Search (AltÄ±n Oran Arama) ile belirlenir.

import numpy as np
import math
import matplotlib.pyplot as plt

# ğŸ¯ AmaÃ§ fonksiyon
def f(x): 
    return 3 + (x[0]-1.5*x[1])**2 + (x[1]-2)**2

# ğŸ“ˆ Gradyan (1. tÃ¼rev)
def gradf(x):
    return np.array([
        2 * (x[0] - 1.5 * x[1]),
        -3 * (x[0] - 1.5 * x[1]) + 2 * (x[1] - 2)
    ])

# ğŸ“Œ Golden Section Search (Tek deÄŸiÅŸkenli optimizasyon)
def GSmain(f_line, xk, pk):
    xalt = 0
    xust = 4
    dx = 0.00001
    alpha = (1 + math.sqrt(5)) / 2
    tau = 1 - 1 / alpha
    epsilon = dx / (xust - xalt)
    N = round(-2.078 * math.log(epsilon))

    def f1d(s):  # f(x + s*p)
        return f_line(xk + s * pk)

    x1 = xalt + tau * (xust - xalt)
    x2 = xust - tau * (xust - xalt)
    f1 = f1d(x1)
    f2 = f1d(x2)

    for _ in range(N):
        if f1 > f2:
            xalt = x1
            x1 = x2
            f1 = f2
            x2 = xust - tau * (xust - xalt)
            f2 = f1d(x2)
        else:
            xust = x2
            x2 = x1
            f2 = f1
            x1 = xalt + tau * (xust - xalt)
            f1 = f1d(x1)

    return 0.5 * (x1 + x2)  # Optimal adÄ±m boyutu

# ğŸ”§ BaÅŸlangÄ±Ã§ deÄŸerleri
x = np.array([-5.4, 1.7])  # BaÅŸlangÄ±Ã§ noktasÄ±
X1 = [x[0]]  # Ä°zlenen x1 deÄŸerleri
X2 = [x[1]]  # Ä°zlenen x2 deÄŸerleri
Nmax = 10000
epsilon1 = 1e-9
epsilon2 = 1e-9
epsilon3 = 1e-9
k = 0

# ğŸ” Iteratif optimizasyon
while True:
    k += 1
    pk = -gradf(x)               # Gradyan yÃ¶nÃ¼nde ters yÃ¶nde ilerleme
    sk = GSmain(f, x, pk)        # Golden section ile optimum adÄ±m uzunluÄŸu
    x_new = x + sk * pk          # Yeni nokta

    # Ä°terasyon bilgisi
    print(f"Iterasyon {k:3d}: x = {x}, f(x) = {f(x):.6f}, |grad(f)| = {np.linalg.norm(gradf(x)):.6e}, step = {sk:.6f}")

    # Durma koÅŸullarÄ±
    if k >= Nmax:
        print("ğŸ” Maksimum iterasyon sayÄ±sÄ±na ulaÅŸÄ±ldÄ±.")
        break
    if abs(f(x_new) - f(x)) < epsilon1:
        print("ğŸ“‰ Fonksiyon deÄŸeri yeterince deÄŸiÅŸmedi.")
        break
    if np.linalg.norm(x_new - x) < epsilon2:
        print("ğŸ“ DeÄŸiÅŸkenler yeterince deÄŸiÅŸmedi.")
        break
    if np.linalg.norm(gradf(x_new)) < epsilon3:
        print("âœ… DuraÄŸan noktaya ulaÅŸÄ±ldÄ±.")
        break

    # GÃ¼ncelleme
    x = x_new
    X1.append(x[0])
    X2.append(x[1])

# ğŸ“Š SonuÃ§larÄ± gÃ¶rselleÅŸtir
plt.plot(X1, X2, label='Ä°zlenen yol')
plt.scatter(X1, X2, s=5, c='red', label='Noktalar')
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Modified Newton YÃ¶ntemi ile Ä°yileÅŸme')
plt.legend()
plt.grid(True)
plt.show()
