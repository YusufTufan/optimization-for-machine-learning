# ğŸŒŸ Golden Section Search Algorithm
# Bu yÃ¶ntem, bir fonksiyonun minimum deÄŸerini bulmak iÃ§in kullanÄ±lan sayÄ±sal bir optimizasyon tekniÄŸidir.
# Fibonacci oranÄ±na dayalÄ± olarak aralÄ±ÄŸÄ± sÃ¼rekli daraltarak Ã§Ã¶zÃ¼m arar.

import math

# ğŸ¯ Hedef fonksiyon
def f(x):
    return (x - 1)**2 * (x - 2) * (x - 3)  # Ã‡oklu kÃ¶k iÃ§eren polinom

# ğŸ”§ BaÅŸlangÄ±Ã§ aralÄ±ÄŸÄ±
xalt = 2      # Alt sÄ±nÄ±r
xust = 3      # Ãœst sÄ±nÄ±r

dx = 1e-7     # Hassasiyet (epsilon)
alpha = (1 + math.sqrt(5)) / 2   # AltÄ±n oran
tau = 1 - 1 / alpha              # TamamlayÄ±cÄ± oran

# ğŸ”¢ Maksimum iterasyon sayÄ±sÄ±nÄ± hesapla (yakÄ±nsama tahmini)
epsilon = dx / (xust - xalt)
N = round(-2.078 * math.log(epsilon))

# BaÅŸlangÄ±Ã§ noktalarÄ±nÄ±n belirlenmesi
x1 = xalt + tau * (xust - xalt); f1 = f(x1)
x2 = xust - tau * (xust - xalt); f2 = f(x2)

# ğŸ” Golden Section DÃ¶ngÃ¼sÃ¼
for k in range(N):
    if f1 > f2:
        xalt = x1
        x1 = x2
        f1 = f2
        x2 = xust - tau * (xust - xalt)
        f2 = f(x2)
    else:
        xust = x2
        x2 = x1
        f2 = f1
        x1 = xalt + tau * (xust - xalt)
        f1 = f(x1)

    # Ä°terasyon Ã§Ä±ktÄ±sÄ±
    print(f"{k+1:2d}: x1 = {x1:.4f}, x2 = {x2:.4f}, f1 = {f1:.4f}, f2 = {f2:.4f}")

# ğŸ”š YaklaÅŸÄ±k kÃ¶kÃ¼ hesapla (aralÄ±ÄŸÄ±n ortalamasÄ±)
x = 0.5 * (x1 + x2)
print(f"\nYaklaÅŸÄ±k minimum nokta: x = {x:.4f}")
